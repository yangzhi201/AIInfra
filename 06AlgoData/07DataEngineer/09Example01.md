<!--Copyright © ZOMI 适用于[License](https://github.com/Infrasys-AI/AIInfra)版权许可-->

# 09.案例：LLM 数据工程

本节将介绍几种主流开源模型在数据处理流程与方法上的实践。需要特别说明的是，数据是各大厂商的核心资源，虽然它们通常会开放模型权重，但很少会公开自己的训练数据。因此，大多数技术报告中并不会披露训练数据的具体细节。不过，通过厂商有限的信息披露，我们仍然能够学习和借鉴许多业界先进的数据处理方法。接下来将分别介绍 Qwen2.5、Qwen3、Llama3.1 以及 Gemini 等模型的数据处理流程。

## Llama3.1

- 技术报告：https://arxiv.org/pdf/2407.21783

Llama3.1 在发布的时候被视作为开源之光，达到了当时开源模型的上届。且技术报告中详细的介绍了自己训练数据的相关信息，因此把它作为第一个学习的内容。

###  一、预训练数据处理

预训练是模型学习语言基础规律和世界知识的阶段，其数据处理的目标是构建大规模、高质量、多样化的文本语料库。Llama 3.1 的预训练数据处理可分为**数据来源与筛选**、**清洗与去重**、**数据混合与优化**三个关键步骤。

#### 1.1 数据来源与筛选

Llama 3.1 的预训练数据覆盖多领域、多语言，总规模达**15T tokens**（是 Llama 2 的 8 倍以上），主要来源包括：

- **网页数据**：从互联网收集的文本，涵盖知识、新闻、论坛等内容，是预训练数据的主要来源。
- **代码数据**：包括开源代码仓库（如 GitHub）中的各类编程语言（Python、Java、C++等）代码及注释。
- **推理与数学数据**：包含数学题、逻辑推理题、科学论文等需要复杂推理的文本。
- **多语言数据**：覆盖 176 种语言，重点优化了英语、德语、法语、 Hindi 等 8 种核心语言。

为确保数据质量，Llama 3.1 首先通过**筛选机制**排除低质量来源：
- 移除包含大量个人可识别信息（PII）的网站（如含有身份证号、手机号的域名）；
- 过滤已知包含成人内容、有害信息的域名（基于 Meta 内部安全标准）；
- 剔除低质量文本（如内容重复、逻辑混乱的网页）。

#### 1.2 数据清洗与去重

原始数据往往存在噪声（如重复内容、格式混乱、错误信息），需通过清洗和去重提升质量。Llama 3.1 的处理流程如下：

##### 1.2.1 文本提取与基础清洗

- **网页文本提取**：使用自定义 HTML 解析器从网页中提取核心内容，去除广告、导航栏等“ boilerplate（冗余格式文本）”，同时保留数学公式、代码块的结构（如保留`alt`标签中的数学公式文本）。
- **格式标准化**：移除 markdown 标记（实验发现 markdown 会降低模型在网页数据上的性能），统一文本编码和标点格式。
- **低质量过滤**：通过启发式规则剔除噪声，例如：
  - 移除包含大量重复 n-gram 的文本（如日志、错误信息中的重复字段）；
  - 过滤“脏词”比例过高的文本（如成人网站特有的词汇）；
  - 通过 token 分布的 KL 散度筛选“异常文档”（如包含大量罕见 token 的文本）。

##### 1.2.2 去重处理

重复数据会导致模型过度拟合，降低泛化能力。Llama 3.1 采用**三级去重策略**：
- **URL 级去重**：对同一 URL 的网页，仅保留最新版本；
- **文档级去重**：使用 MinHash 算法计算文档相似度，移除近重复文档（相似度超过阈值的文档）；
- **行级去重**：对文本中的单行内容，若在 3000 万文档中出现超过 6 次，则视为冗余内容并移除（如网站通用的“隐私政策”片段）。

*注：MinHash 是一种快速计算文档相似度的算法，通过将文档映射为短哈希值，可高效比对大规模文档的重复程度。*

##### 1.2.3 领域专属数据处理

针对代码、推理等特殊领域数据，Llama 3.1 设计了**领域专属 pipeline**：
- **代码数据**：通过 DistilRoberta 模型识别包含代码的网页，提取代码块并保留语法结构（如缩进、注释），过滤无法解析的错误代码；
- **推理数据**：重点筛选包含数学推导、科学推理的文本（如物理题解题步骤），通过模型标注确保内容的逻辑连贯性；
- **多语言数据**：使用 fasttext 语言识别模型将文本分类为 176 种语言，然后在单语言内部进行文档级和行级去重，避免跨语言重复。

#### 1.3 数据混合与优化

数据混合比例直接影响模型在不同任务上的性能。Llama 3.1 通过**知识分类**和**缩放定律实验**确定最优混合比例：

- **知识分类**：使用分类器将数据分为“通用知识”“数学与推理”“代码”“多语言”等类别，下调网页中过度代表的类别（如娱乐内容）；
- **缩放定律实验**：训练多个小模型测试不同数据混合比例的效果，预测大模型性能，最终确定混合比例为：
  - 通用知识：50%
  - 数学与推理：25%
  - 代码：17%
  - 多语言：8%

此外，为进一步提升关键能力，Llama 3.1 还采用**退火数据**策略：在预训练后期，使用高比例的高质量代码和数学数据进行微调，显著提升模型在 GSM8K（数学题）等 benchmark 上的性能（8B 模型提升 24%）。

### 二、微调数据处理

预训练模型仅具备基础语言能力，需通过微调（Post-training）对齐人类偏好（如遵循指令、安全无害）。Llama 3.1 的微调数据处理聚焦于**偏好数据**和**SFT 数据**的构建与优化。

#### 2.1 偏好数据处理

偏好数据用于训练模型理解“人类更喜欢什么样的回答”，是对齐模型行为的核心。Llama 3.1 的偏好数据处理流程如下：

##### 2.1.1 数据收集

- **人类标注**：让标注者对比两个模型对同一 prompt 的回答，按“显著更好”“更好”“稍好”“几乎相同”四级评分；
- **编辑优化**：标注者对“更好”的回答进一步编辑（如修正错误、补充细节），形成“编辑后回答 > 原优选回答 > 被拒绝回答”的三级排序。

##### 2.1.2 数据筛选

- 仅保留“显著更好”和“更好”的样本（过滤差异不明显的样本）；
- 确保数据覆盖多领域：通用英语（81.99%）、代码（6.93%）、多语言（5.19%）、推理与工具使用（5.89%）。

#### 2.2 SFT 数据处理

SFT（Supervised Fine-tuning，有监督微调）数据用于教会模型“如何生成符合指令的回答”，Llama 3.1 的 SFT 数据来源与处理如下：

##### 2.2.1 数据来源

- **人类标注对话**：标注者与模型的多轮对话（如问答、代码调试）；
- **拒绝采样（Rejection Sampling）数据**：对同一 prompt 生成 10-30 个回答，用奖励模型（RM）筛选最优结果；
- **合成数据**：由模型自动生成的针对性数据（如数学题解题步骤、代码翻译案例）。

##### 2.2.2 质量控制

- **主题分类**：用 Llama 3 8B 模型将数据分类为“数学推理”“代码生成”等细粒度类别，确保覆盖全面；
- **质量评分**：结合奖励模型（RM）和 Llama 模型的评分（如“准确性”“指令遵循度”），仅保留高分样本；
- **难度筛选**：通过“意图标签（Instag）”和人工标注区分“简单”“中等”“困难”样本，优先保留高难度样本；
- **语义去重**：用 RoBERTa 模型聚类相似对话，在每个聚类中按“质量×难度”排序，仅保留不重复的优质样本。

#### 2.3 特殊能力数据优化

为增强模型在长文本、工具使用等场景的能力，Llama 3.1 针对性处理了特殊数据：

- **长文本数据**：生成 16K-128K tokens 的超长文档问答、摘要数据（如书籍章节总结、代码仓库分析），仅占 SFT 数据的 0.11%但显著提升长上下文理解；
- **工具使用数据**：包含搜索、代码解释器、Wolfram Alpha 等工具调用的对话，标注者需评估“工具调用是否合理”“结果是否正确”；
- **多语言数据**：翻译高质量推理数据（如数学题）到非英语语言，避免“翻译腔”（如德语的语法错误）。

### 三、总结与思考

Llama 3.1 的数据处理流程体现了三个核心原则：
1. **质量优先**：从源头筛选高价值数据，通过多级清洗、去重和评分确保数据纯净度；
2. **多样性平衡**：通过数据混合策略平衡通用知识与专项能力（代码、推理等），避免模型“偏科”；
3. **针对性优化**：对长文本、多语言等特殊场景设计专属数据处理流程，精准提升模型短板。

### 四、思考问题

下面是一些思考问题，大家在学习后可以尝试作答

1. 为什么 Llama 3.1 在预训练中要“逐步增加序列长度”（从 8K 到 128K），而不是直接训练 128K 长文本？（提示：考虑自注意力的计算复杂度与模型适应性）
2. 多语言数据仅占预训练数据的 8%，但 Llama 3.1 仍能支持 8 种语言的高质量输出，这说明数据处理中的哪些步骤起到了关键作用？
3. 合成数据（如模型生成的代码题）在 SFT 中占比很高，你认为合成数据的优势和潜在风险是什么？
4. 对比预训练数据和微调数据的处理目标，为什么预训练更注重“规模与多样性”，而微调更注重“质量与偏好对齐”？

## 参考与引用

- [Qwen2.5 技术报告](https://arxiv.org/pdf/2412.15115)
- [Qwen3 技术报告](https://arxiv.org/pdf/2505.09388)
- [Gemini2.5 技术报告](https://storage.googleapis.com/deepmind-media/gemini/gemini_v2_5_report.pdf)