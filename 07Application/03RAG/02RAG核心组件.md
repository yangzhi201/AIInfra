# RAG核心组件

主要分为三个部分，检索器，检索融合，生成器，下面分别从这三个部分出发，详细介绍每个部分的组件。

## 检索器构建

该过程包括三个步骤：语料库分块、块编码和构建向量数据库。其中，构建向量数据库包括构建 ANN 索引以及以键值对形式存储数据。

### 1.语料库分块（Chunking Corpus）

分块技术通常指将大型文档分割成小的文本块，这是构建检索器过程中的一个不可或缺的关键步骤。分块技术的背后原理是，(1) 用于索引的文本或嵌入应该是语义独立的，包含一个核心思想供模型编码。短文本更容易产生歧义，例如，单词“apple”可以指水果或一家公司。(2) 使用现有的基于 transformer 的模型对长序列文档进行编码会导致相当大的资源开销，而处理较短的文本块可以显著加速编码过程并节省内存成本。因此，分块技术的主要挑战是找到最佳的分块大小，以在文本语义和编码效率之间做出更好的权衡。

分块技术通常指将大型文档分割成小的文本块（Muszynska，2016；Ishiwatari 等人，2017；Gong 等人，2020；Borgeaud 等人，2022；Chen 等人，2022a），这是构建检索器过程中的一个不可或缺的关键步骤。分块技术的背后原理是，(1) 用于索引的文本或嵌入应该是语义独立的，包含一个核心思想供模型编码。短文本更容易产生歧义，例如，单词“apple”可以指水果或一家公司。(2) 使用现有的基于 transformer 的模型对长序列文档进行编码会导致相当大的资源开销，而处理较短的文本块可以显著加速编码过程并节省内存成本。因此，分块技术的主要挑战是找到最佳的分块大小，以在文本语义和编码效率之间做出更好的权衡。
为了解决上述挑战，在确定分块大小时应考虑三个关键点：

(1) 任务偏好。不同的任务可能受益于不同类型的检索片段。例如，问答任务可能更喜欢短短语，而摘要任务可能更喜欢长文档。

(2) 编码器的偏好。不同的编码器模型在处理不同长度的文本时具有不同的编码能力。

(3) 查询偏好。用户的查询长度应与片段大小相匹配，这隐式地将片段中的上下文信息量与查询中的上下文信息量对齐，从而提高查询与检索的相关性。例如，基于短短语的检索数据库对于包含长文档的查询可能毫无用处。

基本上有三种分块技术，包括固定长度的分块、语义分块和基于内容的分块。固定长度的分块是使用长度超参数顺序分割文档的最简单方法。语义分块根据语义切割文档，例如表示句子结束的句号或换行符。基于内容的分块根据独特的结构特征分割文档。例如，电子病历可以根据章节轻松分割，或者编程代码可以根据功能块分割。

### 2.编码块

编码是指将文本块数值化为向量表示（嵌入）。这些嵌入通常捕获块的含义，使检索器能够根据内容相关性而非仅关键词匹配来执行相似性搜索。

根据嵌入的稀疏性，存在两种编码方法，即稀疏编码和密集编码。稀疏编码通过创建大多数元素为零的高维向量来表示文本。基本的稀疏编码是独热编码（Harris and Harris, 2010），它用一个维度与词汇表大小相同的向量来表示一个词，但仅将对应词存在位置的值标记为 1。这种编码产生的嵌入被称为独热向量。其他常见的稀疏编码包括：

(1) 词袋模型（BoW）(Harris, 1954)。这种编码通过用频率计数替换零一计数来改进独热编码。然而，BoW 忽略了文档中的句法和词序，专注于统计信息，因此只能表达有限的语义。

(2) 词语频率-逆文档频率 (TF-IDF) (Rajaraman and Ullman, 2011)。这种编码不仅统计每个词语的出现次数（频率），还会根据该词语在所有文档中的普遍程度（逆文档频率）调整这些计数。TF-IDF 有助于强调那些更能描述文档内容的词语。

(3) BM25（Robertson 和 Zaragoza，2009 年）是一种概率排序算法，用于信息检索中，通过平衡词频、逆文档频率和文档长度归一化来估计文档与搜索查询的相关性，确保即使对于长文档或短文档也能实现稳健的评分。BM25 侧重于词汇匹配，并且计算效率高，使其成为传统搜索引擎的核心基础。

稀疏编码是一种对文本块进行高效编码的方式。然而，这种编码方法可能无法很好地捕捉更深层的语义含义。

稠密编码生成向量，其中每个维度可以捕获一系列语义特征，并且大多数元素是非零浮点数。稠密嵌入通常由（深度）神经网络模型生成。

(1) BERT（Devlin 等人，2019 年）及其变体。

(2) Siamese Encoders。这是一种神经网络，旨在学习输入之间的相似性，通常使用对比学习进行训练。

(3) 基于 LLM 的编码器。这种编码器受益于 LLM 强大的表示能力。LLM 包含数十亿个参数，并在涵盖广泛主题的大量数据上进行预训练，具有先进的语义语言理解能力。

与稀疏编码相比，密集编码利用深度神经网络，特别是转换器（Vaswani 等人，2017 年）来捕获更广泛的语言和语义信息。密集编码在大多数表示场景中得到了广泛应用。

### 3.构建索引

向量数据库中的索引旨在加速搜索与高维查询嵌入相似的数据。与普通数据库中的索引不同，向量数据库中的索引主要关注支持高效的近似最近邻（ANN）搜索，而不是插入、删除和更新等事务操作。索引的关键挑战是在搜索质量和搜索效率之间做出良好的权衡。为了解决这一挑战，算法层面和系统层面都有各种具体的优化可供探索，包括相似性度量选择、嵌入的降维（DR）、高级 ANN 索引、系统级优化、硬件感知优化等。由于篇幅限制，本节讨论对搜索质量和效率产生显著影响的优化。

相似度度量选择。相似度度量是检索器的基本组成部分，用于衡量查询嵌入和片段嵌入之间的相关性程度。相似度度量会影响搜索质量。典型的相似度度量包括余弦相似度、欧几里得相似度和曼哈顿距离。

嵌入降维。降低嵌入的维度可以提高搜索效率，但存在损害语义表示的风险。基本而有效的降维（DR）是主成分分析（PCA）。PCA 是一种简单的统计技术，它将原始数据转换到新的坐标系中，同时保留最重要的特征。另一种流行且高级的降维技术是局部敏感哈希（LSH）。LSH 通过将数据映射到桶中来显著降低维度，但保留了原始输入数据的相似性。LSH 背后的直觉是最近邻将被映射到相同的桶中。与 LSH 不同，产品量化（PQ）（Jégou 等人，2011 年）是另一种流行且有效的 DR 技术，用于近似最近邻（ANN）搜索。PQ 的核心思想是将高维空间划分为更小、独立量化的子空间。每个子空间创建一个由不同量化整数组成的码本，以形成具有代表性的紧凑向量。上述技术能够实现高效的存储和快速近似搜索，但可能会丢失语义信息。 近期研究（Chevalier 等人，2023 年）提出了一种名为 AutoCompressor 的新技术，通过将原始上下文压缩为语义上更短的嵌入来降低嵌入的维度。

高级 ANN 索引。ANN 索引通常指用于组织和管理数据的方法或结构，以便近似最近邻搜索过程在检索质量和检索效率上得到优化。本文将介绍几种高级 ANN 索引技术。

(1) 基于产品量化的 InVerted 文件系统（IVFPQ）（Douze 等人，2024）是一个简单但有效的索引框架，它结合了两种强大的技术，以实现高效且可扩展的 ANN 搜索过程。IVFPQ 的主要思想是首先对数据进行粗粒度划分的聚类，然后将每个聚类内的数据压缩成子向量进行细粒度量化。粗粒度聚类（IVF 组件）显著减少了搜索空间，而细粒度量化（PQ 组件）确保了高检索性能。

(2) 分层可导航小世界 (HNSW) (Malkov and Yashunin, 2020) 采用分层图结构，在高维空间中高效执行近似最近邻 (ANN) 搜索。具体而言，HNSW 将高维向量视为节点，并将它们与其最近邻连接。多层图结构通过概率方法确定，以确保高层节点较少，从而实现高效搜索。

(3) 基于树的索引旨在将高维向量组织成树状结构，例如 KD 树（Ram 和 Sinha，2019 年）、球树（Huang 和 Tung，2023 年）和 VP 树（Liu 和 Wei，2015 年）。典型的基于树的索引是近似最近邻搜索 Oh Yeah（Annoy）（Spotify，2017 年），它使用基于随机投影构建的树森林将向量空间划分为多个超平面，以实现高效的近似最近邻搜索。

### 4.使用键值对构建数据存储

向量数据库中使用的存储数据结构是一种专门化的数据库，它将数据作为键值对集合进行存储和管理，其中键是高维嵌入的唯一标识符，值是特定领域的知识。由于存储数据结构中存储的数据量可能非常大，因此存储引擎（例如 LMDB（LMDB，2014）或 RocksDB（Facebook，2013））应能够高效地检索和持久化数据。对于 ANN 搜索，存储数据结构中的关键点在于应该将什么作为值进行存储。例如，对于问答任务，在将检索添加到提示时，一种简单但有效的方法是将问题嵌入作为键，将问答对作为值进行存储。这有助于生成过程，因为检索被用作模型的示例。最近的研究工作提出了各种最先进的向量数据库，包括索引和存储数据结构，例如 Milvus（Wang 等人，2021b；Guo 等人，2022）、FAISS（Douze 等人，2024；Johnson 等人，2021）、LlamaIndex（Liu，2022）等。

(算法流程图)
