{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b423d7e4",
   "metadata": {},
   "source": [
    "<!--Copyright © ZOMI 适用于[License](https://github.com/Infrasys-AI/AIInfra)版权许可-->\n",
    "\n",
    "# CODE 03:多模态输出采样与控制\n",
    "\n",
    "> 多模态生成模型正在改变我们创造和理解内容的方式，而采样策略则是控制这一过程的隐形艺术家。\n",
    "\n",
    "在当前的人工智能浪潮中，多模态生成模型已经成为内容创作的重要工具。无论是通过文字描述生成图像，还是根据静态图像创建视频，这些模型都展现出了惊人的能力。\n",
    "\n",
    "但你是否曾经好奇，为什么同样的输入提示，有时会产生令人惊艳的结果，有时却平平无奇？这背后往往取决于采样策略的选择。\n",
    "\n",
    "今天我们将深入探讨温度（Temperature）和 Top-P（核采样）两种采样策略如何影响多模态生成模型的输出结果，以及如何通过调整这些参数来平衡生成结果的**多样性**、**创造性**和**质量**。\n",
    "\n",
    "### 1. Temperature 采样\n",
    "\n",
    "温度参数或许是控制生成随机性最直观的方式。它在数学上调整了模型输出概率分布的平滑程度。\n",
    "\n",
    "给定原始概率分布 $P(x_i|x_{<i})$，应用温度参数 $T$ 后的新概率分布为：\n",
    "\n",
    "$$\\hat{P}(x_i|x_{<i}) = \\frac{\\exp(\\frac{z_i}{T})}{\\sum_j \\exp(\\frac{z_j}{T})}$$\n",
    "\n",
    "其中 $z_i$ 是模型输出的 logits 值。\n",
    "\n",
    "**温度参数的影响**：\n",
    "\n",
    "- 当 $T > 1$ 时，概率分布变得更加平滑，生成结果更加多样但可能不够准确\n",
    "- 当 $T < 1$ 时，概率分布更加尖锐，生成结果更加确定但可能缺乏创造性\n",
    "\n",
    "为了更好地理解这一概念，让我们通过代码来实现温度采样的效果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "820f211e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始概率: [0.56937605 0.20946175 0.12704498 0.09411723]\n",
      "温度 0.5 后的概率: [0.8247789  0.11162169 0.04106332 0.02253603]\n",
      "温度 1.0 后的概率: [0.56937605 0.20946175 0.12704498 0.09411723]\n",
      "温度 2.0 后的概率: [0.4023389  0.24403088 0.19005144 0.1635788 ]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
    "os.environ[\"HF_HUB_DISABLE_TELEMETRY\"] = \"1\"\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def apply_temperature(logits, temperature):\n",
    "    if temperature > 0:\n",
    "        # 应用温度缩放\n",
    "        scaled_logits = logits / temperature\n",
    "        # 重新计算 softmax 概率\n",
    "        probs = F.softmax(scaled_logits, dim=-1)\n",
    "        return probs\n",
    "    else:\n",
    "        raise ValueError(\"温度参数必须大于 0\")\n",
    "\n",
    "# 示例用法\n",
    "logits = torch.tensor([2.0, 1.0, 0.5, 0.2])\n",
    "print(\"原始概率:\", F.softmax(logits, dim=-1).numpy())\n",
    "\n",
    "for temp in [0.5, 1.0, 2.0]:\n",
    "    temp_probs = apply_temperature(logits, temp)\n",
    "    print(f\"温度 {temp} 后的概率: {temp_probs.numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c49796",
   "metadata": {},
   "source": [
    "这段代码展示了温度参数如何影响概率分布。当温度值较低时（如 0.5），概率分布更加集中，模型更倾向于选择最高概率的选项；而当温度值较高时（如 2.0），概率分布更加平滑，模型的选择更加多样化。\n",
    "\n",
    "## 2. Top-P 采样\n",
    "\n",
    "Top-P 采样，也称为核采样，选择概率累积超过阈值 p 的最小可能词元集合，然后从这个集合中重新归一化概率并采样。\n",
    "\n",
    "形式上，给定概率分布 $P$ 和阈值 $p ∈ (0, 1]$，我们按概率降序排列，找到最小的集合 $S$ 使得：\n",
    "\n",
    "$$\\sum_{x_i \\in S} P(x_i) \\geq p$$\n",
    "\n",
    "然后从集合 $S$ 中按照重新归一化的概率进行采样。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ab3fcfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始概率: [0.4 0.3 0.2 0.1]\n",
      "Top-P (p=0.7) 后的概率: [0.57142854 0.4285714  0.         0.        ]\n",
      "Top-P (p=0.9) 后的概率: [0.44444445 0.33333334 0.22222222 0.        ]\n"
     ]
    }
   ],
   "source": [
    "def top_p_sampling(probs, p):\n",
    "    # 对概率进行排序\n",
    "    sorted_probs, indices = torch.sort(probs, descending=True)\n",
    "    # 计算累积概率\n",
    "    cumulative_probs = torch.cumsum(sorted_probs, dim=-1)\n",
    "    \n",
    "    # 移除累积概率超过 p 的部分\n",
    "    indices_to_remove = cumulative_probs > p\n",
    "    # 确保至少保留一个 token\n",
    "    indices_to_remove[..., 1:] = indices_to_remove[..., :-1].clone()\n",
    "    indices_to_remove[..., 0] = 0\n",
    "    \n",
    "    # 将需要移除的 token 概率设为 0\n",
    "    sorted_probs[indices_to_remove] = 0\n",
    "    # 重新归一化概率\n",
    "    sorted_probs /= sorted_probs.sum()\n",
    "    \n",
    "    # 恢复到原始顺序\n",
    "    return sorted_probs.scatter(-1, indices, sorted_probs)\n",
    "\n",
    "# 示例用法\n",
    "probs = torch.tensor([0.4, 0.3, 0.2, 0.1])\n",
    "print(\"原始概率:\", probs.numpy())\n",
    "\n",
    "for p in [0.7, 0.9]:\n",
    "    top_p_probs = top_p_sampling(probs, p)\n",
    "    print(f\"Top-P (p={p}) 后的概率: {top_p_probs.numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a3157d",
   "metadata": {},
   "source": [
    "Top-P 采样的优势在于它能够动态调整候选集的大小，既保证了多样性，又避免了选择概率极低的选项。\n",
    "\n",
    "## 3. 文生图应用实践\n",
    "\n",
    "了解了采样策略的基本原理后，让我们看看它们在实际的多模态生成任务中如何应用。我们将使用 Stable Diffusion 模型进行文本到图像的生成实验。\n",
    "\n",
    "首先，我们需要设置环境并加载模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0138e93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yswang/miniforge3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading pipeline components...:  71%|███████▏  | 5/7 [00:06<00:03,  1.96s/it]`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading pipeline components...: 100%|██████████| 7/7 [00:09<00:00,  1.29s/it]\n"
     ]
    }
   ],
   "source": [
    "from diffusers import StableDiffusionXLPipeline\n",
    "import torch\n",
    "\n",
    "# 加载 SDXL 管道\n",
    "pipe = StableDiffusionXLPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-xl-base-1.0\", \n",
    "    torch_dtype=torch.float16,\n",
    "    use_safetensors=True,\n",
    "    variant=\"fp16\"\n",
    ")\n",
    "\n",
    "# 将管道移动到 GPU（如果可用）\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "pipe = pipe.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f79d495",
   "metadata": {},
   "source": [
    "虽然 Stable Diffusion 本身不直接暴露温度参数，但我们可以通过修改生成过程中的随机性来模拟类似效果。实际上，在扩散模型中，类似的随机性控制可以通过调整 guidance_scale 和随机种子来实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc2ca4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:06<00:00,  4.37it/s]\n",
      "100%|██████████| 30/30 [00:05<00:00,  5.50it/s]\n",
      "100%|██████████| 30/30 [00:05<00:00,  5.48it/s]\n",
      "100%|██████████| 30/30 [00:05<00:00,  5.47it/s]\n"
     ]
    }
   ],
   "source": [
    "def generate_images_with_variation(prompt, num_images=4, guidance_scale=7.5):\n",
    "    images = []\n",
    "    for i in range(num_images):\n",
    "        # 使用不同的随机种子\n",
    "        generator = torch.Generator(device=device).manual_seed(i)\n",
    "        \n",
    "        # 生成图像\n",
    "        image = pipe(\n",
    "            prompt=prompt,\n",
    "            num_inference_steps=30,\n",
    "            guidance_scale=guidance_scale,\n",
    "            generator=generator,\n",
    "        ).images[0]\n",
    "        \n",
    "        images.append(image)\n",
    "    \n",
    "    return images\n",
    "\n",
    "# 设置生成参数\n",
    "prompt = \"一个美丽的日落海滩，有椰子树和金色的沙滩\"\n",
    "negative_prompt = \"模糊，失真，低质量\"\n",
    "\n",
    "# 生成图像\n",
    "images = generate_images_with_variation(prompt)\n",
    "# 保存图像\n",
    "for i, img in enumerate(images):\n",
    "    img.save(f\"./images/CODE03generated_{i}.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eacac3c",
   "metadata": {},
   "source": [
    "在实际应用中，我们往往需要更精细的控制，而不仅仅是调整随机种子。多模态生成的可控性技术正在不断发展，例如通过 ControlNet 实现空间精准定位，通过 LoRA 注入特定规则，以及通过 CLIP 进行情感校准等方法。\n",
    "\n",
    "## 4. 多模态实验\n",
    "\n",
    "除了文生图应用，采样策略也对多模态语言模型的输出有重要影响。让我们以视觉语言模型为例，看看不同采样参数如何影响模型生成的描述。\n",
    "\n",
    "我们将使用 Qwen-VL 模型进行图文对话实验，观察不同温度和 Top-P 参数如何影响生成的图像描述。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccc46e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> 加载 Processor ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<00:00, 5940.94it/s]\n",
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<00:00, 5983.32it/s]\n",
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<00:00, 6087.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> 加载 Model（FP16 + CUDA） ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 5/5 [00:03<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====== 最终结果汇总 ======\n",
      "\n",
      ">>> 低温度 / 高Top-P：\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "描述这张图片的内容、场景和细节\n",
      "assistant\n",
      "这张图片展示了一位身穿传统汉服的女性，背景是一幅山水画。画面中的女子长发披肩，头戴花饰，身着白色上衣和绿色下裙，腰间系有红色腰带，整体服饰典雅大方。她的姿态优雅，右手轻轻抬起，似乎在欣赏周围的景色。\n",
      "\n",
      "背景是一幅水墨山水画，山峦起伏，树木错落有致，远处的树木呈现出秋天特有的橙红色，与前景的白色形成鲜明对比。天空中飘着淡淡的云雾，给人一种宁静而神秘的感觉。左上角有一个金色的大字“梦”，右上角有一个红色的方形印章，上面写着“云”。左侧还有一些书法文字，可能是作者的名字或题词。\n",
      "\n",
      "整体画面充满了古典美，仿佛将观众带入了一个古代的梦境之中。\n",
      "\n",
      "\n",
      ">>> 中温度 / 高Top-P：\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "描述这张图片的内容、场景和细节\n",
      "assistant\n",
      "这张图片是一幅古风插画，描绘了一位身穿传统汉服的女性站在山间。她的服装主要是白色，带有红色的长袖和腰带，下身穿着绿色的裙摆，裙摆上有精美的花纹装饰。她的头发乌黑且长，编成了发髻，发髻上插有几朵粉色的花。\n",
      "\n",
      "背景是秋天的景象，树木呈现出橙红色的叶子，远处的山脉和岩石也显得朦胧而神秘。天空中有云雾缭绕，增添了画面的梦幻感。左侧有一些中文书法和印章，右上角也有一个红色的方形印章，上面写有汉字。\n",
      "\n",
      "整体色调以灰、白、红、绿为主，给人一种宁静而高雅的感觉。\n",
      "\n",
      "\n",
      ">>> 高温度 / 高Top-P：\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "描述这张图片的内容、场景和细节\n",
      "assistant\n",
      "这张图片是一幅古典风格的中国画，画面中的主要内容是一位身穿传统服饰的女子，背景是山水景色。以下是图片的详细描述：\n",
      "\n",
      "1. **人物**：\n",
      "   - 图片中央有一位年轻女性，她穿着传统的汉服，长发披肩，发饰上有花朵装饰。\n",
      "   - 她的姿态优雅，右手似乎拿着一把折扇，衣袂随风飘扬。\n",
      "\n",
      "2. **服饰**：\n",
      "   - 女子的上衣主要是白色的，袖口和领边有红色的部分装饰，腰间围着绿色的花纹长带，下身是裙装，裙摆宽大，飘逸。\n",
      "\n",
      "3. **背景**：\n",
      "   - 背景是一幅山石树木的山水画，树木的颜色以橘红色为主，给人一种秋天的感觉。\n",
      "   - 山石错落有致，云雾缭绕，显得宁静而深远。\n",
      "\n",
      "4. **装饰元素**：\n",
      "   - 左侧有一些中文书法，字体娟秀典雅，配有红色的印章。\n",
      "   - 右上角也有一块红底白字的方形标识，内写着“金盏”。\n",
      "\n",
      "5. **整体氛围**：\n",
      "   - 整个画面色调柔和，充满了古典的\n",
      "\n",
      "\n",
      ">>> 中温度 / 低Top-P：\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "描述这张图片的内容、场景和细节\n",
      "assistant\n",
      "这张图片展示了一位身穿传统汉服的女性，背景是一幅山水画。她的服饰主要是白色和红色相间的长袍，腰间系着一条红色的腰带，脚上穿着绿色的鞋子。她的头发乌黑亮丽，披散在肩上，并用红色的发饰点缀。\n",
      "\n",
      "背景中的山峦和树木色彩斑斓，既有白色的雪景，也有橙色的枫叶，营造出一种秋天的氛围。画面左侧有一些书法文字，右侧有一个红色的印章，印章上有金色的文字。整体画面充满了古典美，给人一种宁静而优雅的感觉。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, AutoModelForVision2Seq\n",
    "# ======================\n",
    "# 模型路径\n",
    "# ======================\n",
    "MODEL_PATH = \"Qwen/Qwen2.5-VL-7B-Instruct\"\n",
    "\n",
    "# ======================\n",
    "# 自动下载 processor 和模型\n",
    "# ======================\n",
    "print(\">>> 加载 Processor ...\")\n",
    "processor = AutoProcessor.from_pretrained(MODEL_PATH, trust_remote_code=True)\n",
    "\n",
    "print(\">>> 加载 Model（FP16 + CUDA） ...\")\n",
    "model = AutoModelForVision2Seq.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"cuda:1\",   # 自动放到GPU\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "# ======================\n",
    "# 加载图片\n",
    "# ======================\n",
    "def load_image(path):\n",
    "    return Image.open(path).convert(\"RGB\")\n",
    "\n",
    "\n",
    "# ======================\n",
    "# 生成描述（多组 sampling）\n",
    "# ======================\n",
    "def generate_descriptions(image_path, prompt_text, sampling_configs):\n",
    "    image = load_image(image_path)\n",
    "\n",
    "    results = []\n",
    "    for cfg in sampling_configs:\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"image\", \"image\": image},\n",
    "                    {\"type\": \"text\", \"text\": prompt_text},\n",
    "                ],\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        # 步骤1：生成 chat 模板文本\n",
    "        chat_text = processor.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,        # or tokenize=True if你想直接tokenize\n",
    "            add_generation_prompt=True,\n",
    "            return_dict=False,     # 默认返回字符串\n",
    "        )\n",
    "\n",
    "        # 步骤2：把文本和图片一起传入 processor\n",
    "        inputs = processor(\n",
    "            text=[chat_text],           # 注意：这里是 list of str, 因为这个版本的Qwen需要这种数据\n",
    "            images=[image],             # list of PIL Images 对应\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        # 移动到设备 + dtype\n",
    "        inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "        # 生成\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=256,\n",
    "            do_sample=True,\n",
    "            temperature=cfg[\"temperature\"],\n",
    "            top_p=cfg[\"top_p\"],\n",
    "        )\n",
    "\n",
    "        # decode\n",
    "        # 如果你用的是 batch，那么用 batch_decode\n",
    "        text = processor.batch_decode(output, skip_special_tokens=True)[0]\n",
    "        results.append((cfg[\"name\"], text))\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "# ======================\n",
    "# 定义采样配置（可改）\n",
    "# ======================\n",
    "sampling_configs = [\n",
    "    {\"temperature\": 0.1, \"top_p\": 0.9, \"name\": \"低温度 / 高Top-P\"},\n",
    "    {\"temperature\": 0.7, \"top_p\": 0.9, \"name\": \"中温度 / 高Top-P\"},\n",
    "    {\"temperature\": 1.2, \"top_p\": 0.9, \"name\": \"高温度 / 高Top-P\"},\n",
    "    {\"temperature\": 0.7, \"top_p\": 0.3, \"name\": \"中温度 / 低Top-P\"},\n",
    "]\n",
    "\n",
    "\n",
    "# ======================\n",
    "# 运行（你只要改图片路径）\n",
    "# ======================\n",
    "image_path = \"./images/CODE03generated_0.png\"\n",
    "prompt_text = \"描述这张图片的内容、场景和细节\"\n",
    "\n",
    "descriptions = generate_descriptions(image_path, prompt_text, sampling_configs)\n",
    "\n",
    "# ======================\n",
    "# 输出结果\n",
    "# ======================\n",
    "print(\"\\n====== 最终结果汇总 ======\")\n",
    "for name, text in descriptions:\n",
    "    print(f\"\\n>>> {name}：\\n{text}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62da343b",
   "metadata": {},
   "source": [
    "通过这个实验，我们可以观察到不同采样配置下模型生成的描述有何不同。低温度配置往往产生更加保守和确定的描述，而高温度配置则可能产生更加创造性和多样化的描述，但也可能增加不相关或虚构内容的风险。\n",
    "\n",
    "## 5. 评估生成结果\n",
    "\n",
    "评估多模态生成结果的质量是一个复杂的任务，需要从多个维度进行考量。常用的评估指标包括：\n",
    "\n",
    "1.  **模态对齐度（MDA）**：衡量生成内容与输入提示之间的一致性。\n",
    "2.  **细节保真度（DF）**：评估生成内容的细节丰富程度和准确性。\n",
    "3.  **多样性**：衡量不同生成结果之间的差异程度。\n",
    "4.  **创造性**：评估生成内容的新颖性和创新程度。\n",
    "\n",
    "我们可以通过计算一些定量指标来评估生成结果的多样性："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a8f03ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "def calculate_diversity(descriptions):\n",
    "    \"\"\"\n",
    "    计算生成描述的多样性指标\n",
    "    \"\"\"\n",
    "    all_words = []\n",
    "    for item in descriptions:\n",
    "        # 假设每个 item 是 (标签, 描述字符串)\n",
    "        if isinstance(item, tuple) and len(item) >= 2:\n",
    "            desc = item[1]\n",
    "        if not isinstance(desc, str):\n",
    "            raise ValueError(f\"Expected description to be str, but got {type(desc).__name__}: {desc!r}\")\n",
    "        words = desc.lower().split()\n",
    "        all_words.extend(words)\n",
    "    \n",
    "    # 计算词汇总量和唯一词汇量\n",
    "    total_words = len(all_words)\n",
    "    unique_words = len(set(all_words))\n",
    "    lexical_diversity = unique_words / total_words if total_words > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        \"lexical_diversity\": lexical_diversity,\n",
    "        \"unique_words\": unique_words,\n",
    "        \"total_words\": total_words\n",
    "    }\n",
    "\n",
    "# 计算生成描述的多样性\n",
    "diversity_metrics = calculate_diversity(descriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f844d01",
   "metadata": {},
   "source": [
    "除了这些定量指标，人工评估仍然是评估生成质量的重要方式，特别是对于创造性和审美价值的判断。\n",
    "\n",
    "## 6. 总结与思考\n",
    "\n",
    "采样策略在多模态生成中扮演着至关重要的角色，它们像是隐形的艺术家，默默地影响着生成结果的多样性、创造性和质量。通过理解和掌握温度参数和 Top-P 采样等策略，我们能够更好地驾驭多模态生成模型，创造出更加符合期望的内容。\n",
    "\n",
    "需要注意的是，参数调整并非万能，它需要在模型能力、任务需求和使用场景之间找到平衡点。有时候，**创造力的提升可能会以降低精确性为代价**，而**过于追求确定性又可能抑制创新**。这正是多模态生成既是一门科学也是一门艺术的原因。\n",
    "\n",
    "希望本文能够为你理解和应用采样策略提供有益的指导，帮助你在多模态生成的探索之旅中走得更远。记住，最好的参数配置往往来自于不断的实验和调整，而不是一成不变的公式。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
