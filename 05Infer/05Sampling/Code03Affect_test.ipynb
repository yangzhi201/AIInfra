{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b423d7e4",
   "metadata": {},
   "source": [
    "<!--Copyright © ZOMI 适用于[License](https://github.com/Infrasys-AI/AIInfra)版权许可-->\n",
    "\n",
    "# CODE 03:多模态输出采样与控制\n",
    "\n",
    "> 多模态生成模型正在改变我们创造和理解内容的方式，而采样策略则是控制这一过程的隐形艺术家。\n",
    "\n",
    "在当前的人工智能浪潮中，多模态生成模型已经成为内容创作的重要工具。无论是通过文字描述生成图像，还是根据静态图像创建视频，这些模型都展现出了惊人的能力。\n",
    "\n",
    "但你是否曾经好奇，为什么同样的输入提示，有时会产生令人惊艳的结果，有时却平平无奇？这背后往往取决于采样策略的选择。\n",
    "\n",
    "今天我们将深入探讨温度（Temperature）和 Top-P（核采样）两种采样策略如何影响多模态生成模型的输出结果，以及如何通过调整这些参数来平衡生成结果的**多样性**、**创造性**和**质量**。\n",
    "\n",
    "### 1. Temperature 采样\n",
    "\n",
    "温度参数或许是控制生成随机性最直观的方式。它在数学上调整了模型输出概率分布的平滑程度。\n",
    "\n",
    "给定原始概率分布 $P(x_i|x_{<i})$，应用温度参数 $T$ 后的新概率分布为：\n",
    "\n",
    "$$\\hat{P}(x_i|x_{<i}) = \\frac{\\exp(\\frac{z_i}{T})}{\\sum_j \\exp(\\frac{z_j}{T})}$$\n",
    "\n",
    "其中 $z_i$ 是模型输出的 logits 值。\n",
    "\n",
    "**温度参数的影响**：\n",
    "\n",
    "- 当 $T > 1$ 时，概率分布变得更加平滑，生成结果更加多样但可能不够准确\n",
    "- 当 $T < 1$ 时，概率分布更加尖锐，生成结果更加确定但可能缺乏创造性\n",
    "\n",
    "为了更好地理解这一概念，让我们通过代码来实现温度采样的效果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "820f211e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始概率: [0.56937605 0.20946175 0.12704498 0.09411723]\n",
      "温度 0.5 后的概率: [0.8247789  0.11162169 0.04106332 0.02253603]\n",
      "温度 1.0 后的概率: [0.56937605 0.20946175 0.12704498 0.09411723]\n",
      "温度 2.0 后的概率: [0.4023389  0.24403088 0.19005144 0.1635788 ]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
    "os.environ[\"HF_HUB_DISABLE_TELEMETRY\"] = \"1\"\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def apply_temperature(logits, temperature):\n",
    "    if temperature > 0:\n",
    "        # 应用温度缩放\n",
    "        scaled_logits = logits / temperature\n",
    "        # 重新计算 softmax 概率\n",
    "        probs = F.softmax(scaled_logits, dim=-1)\n",
    "        return probs\n",
    "    else:\n",
    "        raise ValueError(\"温度参数必须大于 0\")\n",
    "\n",
    "# 示例用法\n",
    "logits = torch.tensor([2.0, 1.0, 0.5, 0.2])\n",
    "print(\"原始概率:\", F.softmax(logits, dim=-1).numpy())\n",
    "\n",
    "for temp in [0.5, 1.0, 2.0]:\n",
    "    temp_probs = apply_temperature(logits, temp)\n",
    "    print(f\"温度 {temp} 后的概率: {temp_probs.numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c49796",
   "metadata": {},
   "source": [
    "这段代码展示了温度参数如何影响概率分布。当温度值较低时（如 0.5），概率分布更加集中，模型更倾向于选择最高概率的选项；而当温度值较高时（如 2.0），概率分布更加平滑，模型的选择更加多样化。\n",
    "\n",
    "## 2. Top-P 采样\n",
    "\n",
    "Top-P 采样，也称为核采样，选择概率累积超过阈值 p 的最小可能词元集合，然后从这个集合中重新归一化概率并采样。\n",
    "\n",
    "形式上，给定概率分布 $P$ 和阈值 $p ∈ (0, 1]$，我们按概率降序排列，找到最小的集合 $S$ 使得：\n",
    "\n",
    "$$\\sum_{x_i \\in S} P(x_i) \\geq p$$\n",
    "\n",
    "然后从集合 $S$ 中按照重新归一化的概率进行采样。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ab3fcfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始概率: [0.4 0.3 0.2 0.1]\n",
      "Top-P (p=0.7) 后的概率: [0.57142854 0.4285714  0.         0.        ]\n",
      "Top-P (p=0.9) 后的概率: [0.44444445 0.33333334 0.22222222 0.        ]\n"
     ]
    }
   ],
   "source": [
    "def top_p_sampling(probs, p):\n",
    "    # 对概率进行排序\n",
    "    sorted_probs, indices = torch.sort(probs, descending=True)\n",
    "    # 计算累积概率\n",
    "    cumulative_probs = torch.cumsum(sorted_probs, dim=-1)\n",
    "    \n",
    "    # 移除累积概率超过 p 的部分\n",
    "    indices_to_remove = cumulative_probs > p\n",
    "    # 确保至少保留一个 token\n",
    "    indices_to_remove[..., 1:] = indices_to_remove[..., :-1].clone()\n",
    "    indices_to_remove[..., 0] = 0\n",
    "    \n",
    "    # 将需要移除的 token 概率设为 0\n",
    "    sorted_probs[indices_to_remove] = 0\n",
    "    # 重新归一化概率\n",
    "    sorted_probs /= sorted_probs.sum()\n",
    "    \n",
    "    # 恢复到原始顺序\n",
    "    return sorted_probs.scatter(-1, indices, sorted_probs)\n",
    "\n",
    "# 示例用法\n",
    "probs = torch.tensor([0.4, 0.3, 0.2, 0.1])\n",
    "print(\"原始概率:\", probs.numpy())\n",
    "\n",
    "for p in [0.7, 0.9]:\n",
    "    top_p_probs = top_p_sampling(probs, p)\n",
    "    print(f\"Top-P (p={p}) 后的概率: {top_p_probs.numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a3157d",
   "metadata": {},
   "source": [
    "Top-P 采样的优势在于它能够动态调整候选集的大小，既保证了多样性，又避免了选择概率极低的选项。\n",
    "\n",
    "## 3. 文生图应用实践\n",
    "\n",
    "了解了采样策略的基本原理后，让我们看看它们在实际的多模态生成任务中如何应用。我们将使用 Stable Diffusion 模型进行文本到图像的生成实验。\n",
    "\n",
    "首先，我们需要设置环境并加载模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0138e93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 19 files: 100%|██████████| 19/19 [04:07<00:00, 13.03s/it]\n",
      "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.33it/s]\n"
     ]
    }
   ],
   "source": [
    "from diffusers import StableDiffusionXLPipeline\n",
    "import torch\n",
    "\n",
    "# 加载 SDXL 管道\n",
    "pipe = StableDiffusionXLPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-xl-base-1.0\", \n",
    "    torch_dtype=torch.float16,\n",
    "    use_safetensors=True,\n",
    "    variant=\"fp16\"\n",
    ")\n",
    "\n",
    "# 将管道移动到 GPU（如果可用）\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "pipe = pipe.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f79d495",
   "metadata": {},
   "source": [
    "虽然 Stable Diffusion 本身不直接暴露温度参数，但我们可以通过修改生成过程中的随机性来模拟类似效果。实际上，在扩散模型中，类似的随机性控制可以通过调整 guidance_scale 和随机种子来实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc2ca4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:00<00:12,  2.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:22<00:00,  1.34it/s]\n",
      "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl.py:748: FutureWarning: `upcast_vae` is deprecated and will be removed in version 1.0.0. `upcast_vae` is deprecated. Please use `pipe.vae.to(torch.float32)`. For more details, please refer to: https://github.com/huggingface/diffusers/pull/12619#issue-3606633695.\n",
      "  deprecate(\n",
      "100%|██████████| 30/30 [00:22<00:00,  1.31it/s]\n",
      "100%|██████████| 30/30 [00:23<00:00,  1.29it/s]\n",
      "100%|██████████| 30/30 [00:23<00:00,  1.29it/s]\n"
     ]
    }
   ],
   "source": [
    "def generate_images_with_variation(prompt, num_images=4, guidance_scale=7.5):\n",
    "    images = []\n",
    "    for i in range(num_images):\n",
    "        # 使用不同的随机种子\n",
    "        generator = torch.Generator(device=device).manual_seed(i)\n",
    "        \n",
    "        # 生成图像\n",
    "        image = pipe(\n",
    "            prompt=prompt,\n",
    "            num_inference_steps=30,\n",
    "            guidance_scale=guidance_scale,\n",
    "            generator=generator,\n",
    "        ).images[0]\n",
    "        \n",
    "        images.append(image)\n",
    "    \n",
    "    return images\n",
    "\n",
    "# 设置生成参数\n",
    "prompt = \"一个美丽的日落海滩，有椰子树和金色的沙滩\"\n",
    "negative_prompt = \"模糊，失真，低质量\"\n",
    "\n",
    "# 生成图像\n",
    "images = generate_images_with_variation(prompt)\n",
    "# 保存图像\n",
    "for i, img in enumerate(images):\n",
    "    img.save(f\"./workspace/images/CODE03generated_{i}.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eacac3c",
   "metadata": {},
   "source": [
    "在实际应用中，我们往往需要更精细的控制，而不仅仅是调整随机种子。多模态生成的可控性技术正在不断发展，例如通过 ControlNet 实现空间精准定位，通过 LoRA 注入特定规则，以及通过 CLIP 进行情感校准等方法。\n",
    "\n",
    "## 4. 多模态实验\n",
    "\n",
    "除了文生图应用，采样策略也对多模态语言模型的输出有重要影响。让我们以视觉语言模型为例，看看不同采样参数如何影响模型生成的描述。\n",
    "\n",
    "我们将使用 Qwen-VL 模型进行图文对话实验，观察不同温度和 Top-P 参数如何影响生成的图像描述。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ccc46e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> 加载 Processor ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<00:00, 9892.23it/s]\n",
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<00:00, 12018.06it/s]\n",
      "The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. Note that this behavior will be extended to all models in a future release.\n",
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<00:00, 10034.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> 加载 Model（FP16 + CUDA） ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/transformers/models/auto/modeling_auto.py:2242: FutureWarning: The class `AutoModelForVision2Seq` is deprecated and will be removed in v5.0. Please use `AutoModelForImageTextToText` instead.\n",
      "  warnings.warn(\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████| 5/5 [01:09<00:00, 13.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====== 最终结果汇总 ======\n",
      "\n",
      ">>> 低温度 / 高Top-P：\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "描述这张图片的内容、场景和细节\n",
      "assistant\n",
      "这张图片描绘了一位身穿传统服饰的女子，背景是一个充满诗意的自然景观。女子的服饰华丽，颜色以白色为主，带有粉色和橙色的装饰，显得非常优雅。她的长发披肩，姿态优雅，似乎在欣赏周围的景色。\n",
      "\n",
      "背景中有一棵大树，树上开满了粉红色的花朵，可能是樱花或桃花，给人一种春天的感觉。树干粗壮，枝叶繁茂，与女子的服饰形成了鲜明的对比。远处可以看到一些山峦，山间云雾缭绕，增添了几分神秘感。地面上有几片落叶，可能是秋天的景象，但整体色调仍然偏向温暖的色彩。\n",
      "\n",
      "整个画面充满了古典美，仿佛将观众带入了一个古代的山水画中，展现了人与自然和谐共处的美好画面。\n",
      "\n",
      "\n",
      ">>> 中温度 / 高Top-P：\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "描述这张图片的内容、场景和细节\n",
      "assistant\n",
      "这张图片描绘了一位身穿传统汉服的女性，站在一个宁静的湖边。她的长发披肩，衣袂飘逸，背景中有一棵开满粉色花朵的大树，树枝错综复杂，与湖水相映成趣。\n",
      "\n",
      "1. **人物**：图片中的女子身着一袭精致的白色汉服，裙摆宽大，显得非常优雅。她的姿态优雅，右手轻轻抚摸着树干，仿佛在与自然对话。\n",
      "\n",
      "2. **环境**：画面背景是一个宁静的湖景，湖面波光粼粼，远处的山脉隐约可见，增添了几分神秘感。树木上盛开的粉色花朵为整个画面增添了生机与活力，与湖水的颜色形成鲜明对比。\n",
      "\n",
      "3. **色彩**：整体色调柔和，以粉色、白色和灰色为主，给人一种宁静和谐的感觉。粉色的花朵、白色的衣裳和灰色的树木相互映衬，营造出一种古典而梦幻的氛围。\n",
      "\n",
      "4. **细节**：树叶随风飘落，仿佛在诉说着季节的变换，增加了画面的层次感。此外，女子的手势也传达出一种宁静与淡然的心境，仿佛置身于世外桃源。\n",
      "\n",
      "这张图片通过细腻的\n",
      "\n",
      "\n",
      ">>> 高温度 / 高Top-P：\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "描述这张图片的内容、场景和细节\n",
      "assistant\n",
      "这张图片是一幅古风插画，描绘了一位身穿传统汉服的女子站在自然景观中。女子的服饰精致华丽，颜色为浅灰色和橙色相间，长发披肩，姿态优雅。\n",
      "\n",
      "背景是一片宁静的湖景，湖边有几棵古老的树木，枝干扭曲苍劲，树叶呈现出红色和白色的色调，象征着不同的季节变化。天空中飘落的花瓣增添了画面的诗意氛围，给人一种清新淡雅的感觉。\n",
      "\n",
      "远处可以看到朦胧的山峦，增加了画面的空间层次感，使得整个场景更加深远和富有意境。水面上轻轻飘浮的落叶，使湖面更加生动。\n",
      "\n",
      "整体来看，这幅图具有浓厚的传统艺术气息，融合了自然景色与人物形象，展现了中国古典美的精髓。\n",
      "\n",
      "\n",
      ">>> 中温度 / 低Top-P：\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "描述这张图片的内容、场景和细节\n",
      "assistant\n",
      "这张图片描绘了一位身穿传统服饰的女子，背景是一个充满诗意的自然景观。女子穿着一件白色长袍，袍子上有淡粉色的花纹装饰，显得非常优雅。她的长发披肩，姿态优雅，似乎在欣赏周围的景色。\n",
      "\n",
      "背景中有两棵大树，一棵树上开满了粉红色的花朵，另一棵树则呈现出秋天的景象，树叶变成了橙红色。这些树木的枝干粗壮，显得古老而坚韧。远处可以看到一些山峦，山间云雾缭绕，给人一种宁静而神秘的感觉。地面上有一些落叶，增添了秋天的气息。\n",
      "\n",
      "整体画面色彩柔和，充满了古典美和自然的和谐。女子的姿态和背景的自然景观相结合，营造出一种宁静、悠远的氛围。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, AutoModelForVision2Seq\n",
    "# ======================\n",
    "# 模型路径\n",
    "# ======================\n",
    "MODEL_PATH = \"Qwen/Qwen2.5-VL-7B-Instruct\"\n",
    "\n",
    "# ======================\n",
    "# 自动下载 processor 和模型\n",
    "# ======================\n",
    "print(\">>> 加载 Processor ...\")\n",
    "processor = AutoProcessor.from_pretrained(MODEL_PATH, trust_remote_code=True)\n",
    "\n",
    "print(\">>> 加载 Model（FP16 + CUDA） ...\")\n",
    "model = AutoModelForVision2Seq.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"cuda:0\",   # 自动放到GPU\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "# ======================\n",
    "# 加载图片\n",
    "# ======================\n",
    "def load_image(path):\n",
    "    return Image.open(path).convert(\"RGB\")\n",
    "\n",
    "\n",
    "# ======================\n",
    "# 生成描述（多组 sampling）\n",
    "# ======================\n",
    "def generate_descriptions(image_path, prompt_text, sampling_configs):\n",
    "    image = load_image(image_path)\n",
    "\n",
    "    results = []\n",
    "    for cfg in sampling_configs:\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"image\", \"image\": image},\n",
    "                    {\"type\": \"text\", \"text\": prompt_text},\n",
    "                ],\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        # 步骤1：生成 chat 模板文本\n",
    "        chat_text = processor.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,        # or tokenize=True if你想直接tokenize\n",
    "            add_generation_prompt=True,\n",
    "            return_dict=False,     # 默认返回字符串\n",
    "        )\n",
    "\n",
    "        # 步骤2：把文本和图片一起传入 processor\n",
    "        inputs = processor(\n",
    "            text=[chat_text],           # 注意：这里是 list of str, 因为这个版本的Qwen需要这种数据\n",
    "            images=[image],             # list of PIL Images 对应\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        # 移动到设备 + dtype\n",
    "        inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "        # 生成\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=256,\n",
    "            do_sample=True,\n",
    "            temperature=cfg[\"temperature\"],\n",
    "            top_p=cfg[\"top_p\"],\n",
    "        )\n",
    "\n",
    "        # decode\n",
    "        # 如果你用的是 batch，那么用 batch_decode\n",
    "        text = processor.batch_decode(output, skip_special_tokens=True)[0]\n",
    "        results.append((cfg[\"name\"], text))\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "# ======================\n",
    "# 定义采样配置（可改）\n",
    "# ======================\n",
    "sampling_configs = [\n",
    "    {\"temperature\": 0.1, \"top_p\": 0.9, \"name\": \"低温度 / 高Top-P\"},\n",
    "    {\"temperature\": 0.7, \"top_p\": 0.9, \"name\": \"中温度 / 高Top-P\"},\n",
    "    {\"temperature\": 1.2, \"top_p\": 0.9, \"name\": \"高温度 / 高Top-P\"},\n",
    "    {\"temperature\": 0.7, \"top_p\": 0.3, \"name\": \"中温度 / 低Top-P\"},\n",
    "]\n",
    "\n",
    "\n",
    "# ======================\n",
    "# 运行（你只要改图片路径）\n",
    "# ======================\n",
    "image_path = \"./workspace/images/CODE03generated_0.png\"\n",
    "prompt_text = \"描述这张图片的内容、场景和细节\"\n",
    "\n",
    "descriptions = generate_descriptions(image_path, prompt_text, sampling_configs)\n",
    "\n",
    "# ======================\n",
    "# 输出结果\n",
    "# ======================\n",
    "print(\"\\n====== 最终结果汇总 ======\")\n",
    "for name, text in descriptions:\n",
    "    print(f\"\\n>>> {name}：\\n{text}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62da343b",
   "metadata": {},
   "source": [
    "通过这个实验，我们可以观察到不同采样配置下模型生成的描述有何不同。低温度配置往往产生更加保守和确定的描述，而高温度配置则可能产生更加创造性和多样化的描述，但也可能增加不相关或虚构内容的风险。\n",
    "\n",
    "## 5. 评估生成结果\n",
    "\n",
    "评估多模态生成结果的质量是一个复杂的任务，需要从多个维度进行考量。常用的评估指标包括：\n",
    "\n",
    "1.  **模态对齐度（MDA）**：衡量生成内容与输入提示之间的一致性。\n",
    "2.  **细节保真度（DF）**：评估生成内容的细节丰富程度和准确性。\n",
    "3.  **多样性**：衡量不同生成结果之间的差异程度。\n",
    "4.  **创造性**：评估生成内容的新颖性和创新程度。\n",
    "\n",
    "我们可以通过计算一些定量指标来评估生成结果的多样性："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a8f03ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5178571428571429\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "def calculate_diversity(descriptions):\n",
    "    \"\"\"\n",
    "    计算生成描述的多样性指标\n",
    "    \"\"\"\n",
    "    all_words = []\n",
    "    for item in descriptions:\n",
    "        # 假设每个 item 是 (标签, 描述字符串)\n",
    "        if isinstance(item, tuple) and len(item) >= 2:\n",
    "            desc = item[1]\n",
    "        if not isinstance(desc, str):\n",
    "            raise ValueError(f\"Expected description to be str, but got {type(desc).__name__}: {desc!r}\")\n",
    "        words = desc.lower().split()\n",
    "        all_words.extend(words)\n",
    "    \n",
    "    # 计算词汇总量和唯一词汇量\n",
    "    total_words = len(all_words)\n",
    "    unique_words = len(set(all_words))\n",
    "    lexical_diversity = unique_words / total_words if total_words > 0 else 0\n",
    "    print(lexical_diversity)\n",
    "    return {\n",
    "        \"lexical_diversity\": lexical_diversity,\n",
    "        \"unique_words\": unique_words,\n",
    "        \"total_words\": total_words\n",
    "    }\n",
    "\n",
    "# 计算生成描述的多样性\n",
    "diversity_metrics = calculate_diversity(descriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f844d01",
   "metadata": {},
   "source": [
    "除了这些定量指标，人工评估仍然是评估生成质量的重要方式，特别是对于创造性和审美价值的判断。\n",
    "\n",
    "## 6. 总结与思考\n",
    "\n",
    "采样策略在多模态生成中扮演着至关重要的角色，它们像是隐形的艺术家，默默地影响着生成结果的多样性、创造性和质量。通过理解和掌握温度参数和 Top-P 采样等策略，我们能够更好地驾驭多模态生成模型，创造出更加符合期望的内容。\n",
    "\n",
    "需要注意的是，参数调整并非万能，它需要在模型能力、任务需求和使用场景之间找到平衡点。有时候，**创造力的提升可能会以降低精确性为代价**，而**过于追求确定性又可能抑制创新**。这正是多模态生成既是一门科学也是一门艺术的原因。\n",
    "\n",
    "希望本文能够为你理解和应用采样策略提供有益的指导，帮助你在多模态生成的探索之旅中走得更远。记住，最好的参数配置往往来自于不断的实验和调整，而不是一成不变的公式。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
